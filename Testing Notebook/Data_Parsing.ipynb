{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing \n",
    "\n",
    "## The following cells will be debugging and development for a data parsing script utilizing pandas and system commands to access, create, and organize files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_date_parser = lambda x,y,z,a,b: datetime.datetime.strptime(f\"{x} {y} {z} {a} {b}\", \"%Y %m %d %H %M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"..\\\\Data\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame that will be utilized to store all of the parsed data.\n",
    "BigDF = pd.DataFrame()\n",
    "# Store all of the files as a list, in order to access it in the loop appropriately.\n",
    "files = glob.glob(f\"../NREL Data/**/*{2020}.csv\", recursive=True)\n",
    "def dateparse(x): return pd.datetime.strptime(x, '%Y %m %d %H %M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(0, len(files)):\n",
    "    start = time.time()\n",
    "    if len(files) > 2:\n",
    "        DataFile = files.pop()\n",
    "        DataFile2 = files.pop()\n",
    "        Csv_DF = pd.read_csv(DataFile, header=[2], parse_dates={\n",
    "            'Date': [0, 1, 2, 3, 4]}, date_parser=dateparse)\n",
    "        Lat_Lon_DF1 = pd.read_csv(DataFile, nrows=1)\n",
    "        Csv_DF[\"Longitude\"] = Lat_Lon_DF1.Longitude[0]\n",
    "        Csv_DF[\"Latitude\"] = Lat_Lon_DF1.Latitude[0]\n",
    "        Csv_DF2 = pd.read_csv(DataFile2, header=[2], parse_dates={\n",
    "            'Date': [0, 1, 2, 3, 4]}, date_parser=dateparse)\n",
    "        Lat_Lon_DF2 = pd.read_csv(DataFile2, nrows=1)\n",
    "        Csv_DF2[\"Longitude\"] = Lat_Lon_DF2.Longitude[0]\n",
    "        Csv_DF2[\"Latitude\"] = Lat_Lon_DF2.Latitude[0]\n",
    "        BigDF = BigDF.append([Csv_DF, Csv_DF2])\n",
    "        # print(BigDF)\n",
    "    elif len(files) == 1:\n",
    "        DataFile = files.pop()\n",
    "        Csv_DF = pd.read_csv(DataFile, header=[2], parse_dates={\n",
    "            'Date': [0, 1, 2, 3, 4]}, date_parser=dateparse)\n",
    "        Lat_Lon_DF1 = pd.read_csv(DataFile, nrows=1)\n",
    "        Csv_DF[\"Longitude\"] = Lat_Lon_DF1.Longitude[0]\n",
    "        Csv_DF[\"Latitude\"] = Lat_Lon_DF1.Latitude[0]\n",
    "        BigDF = BigDF.append([Csv_DF])\n",
    "        # print(BigDF)\n",
    "\n",
    "Parsed_Data = BigDF.groupby(\n",
    "    [pd.Grouper(key=\"Date\", freq='1D'), \"Latitude\", \"Longitude\"]).mean()\n",
    "# Parsed_Data = Parsed_Data.round(2)\n",
    "print(Parsed_Data)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Elapsed time parsed data: \", (end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time making directory:  0.0009908676147460938\n",
      "Elapsed time making directory:  0.000990152359008789\n"
     ]
    }
   ],
   "source": [
    "for name in [\"DHI\", \"GHI\", \"DNI\", \"Air Temperature\"]:\n",
    "    start = time.time()\n",
    "    if not os.path.isdir(data_dir+\"2020\"+name):\n",
    "        os.makedirs(data_dir+\"2020\"+name)\n",
    "    else:\n",
    "        continue\n",
    "    end = time.time()\n",
    "    print(\"Elapsed time making directory: \", (end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Parsed_Data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28884/511045990.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'latitude'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'longitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mrowIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mParsed_Data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;31m# print(f\"rowIndex[0] = {rowIndex[0]}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# print(f\"rowIndex[1] = {rowIndex[1]}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Parsed_Data' is not defined"
     ]
    }
   ],
   "source": [
    "expected_date = datetime.date(int(2020), 1, 1)\n",
    "\n",
    "day_offset = datetime.timedelta(days=1)\n",
    "for Value in [\"DHI\", \"GHI\", \"DNI\", \"Air Temperature\"]:\n",
    "    start = time.time()\n",
    "    Data = pd.DataFrame(columns=['value', 'latitude', 'longitude'])\n",
    "    for rowIndex, row in Parsed_Data.iterrows():\n",
    "        # print(f\"rowIndex[0] = {rowIndex[0]}\")\n",
    "        # print(f\"rowIndex[1] = {rowIndex[1]}\")\n",
    "        # print(f\"rowIndex[2] = {rowIndex[2]}\")\n",
    "        # print(f\"row = {row}\")\n",
    "        if rowIndex[0].date() == expected_date:\n",
    "            Data = Data.append({'value': row[Value], 'latitude':\n",
    "                                rowIndex[1], 'longitude': rowIndex[2]}, ignore_index=True)\n",
    "            print(Data)\n",
    "        elif expected_date.year > rowIndex[0].date().year and expected_date.day >= 2:\n",
    "            expected_date = datetime.date(int(Year), 1, 1)\n",
    "            # print(f\"Expected date: {expected_date}\")\n",
    "            continue\n",
    "        else:\n",
    "            Data.to_csv(\n",
    "                path_or_buf=f\"{data_dir}{rowIndex[0].strftime('%Y')}{Value}/{Value}{expected_date.strftime('%Y%j')}.csv\",\n",
    "                header=False, index=False, sep=' ')\n",
    "            Data.drop(index=Data.index, inplace=True)\n",
    "            expected_date = expected_date+day_offset\n",
    "            # print(f\"This is the expected date after the offset: {expected_date}\")\n",
    "    print(Data)\n",
    "end = time.time()\n",
    "print(\"Elapsed time file generator: \", (end - start))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solarData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26169997774188913528129c585e07895cdddee0c516055b04c1e80ef12a365c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
